{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345249d9-c7f9-4577-951c-c294c586a3a1",
   "metadata": {},
   "source": [
    "# Install required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "290f3c0c-ec89-41cf-b10d-4a0448d43f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai gradio pandas networkx matplotlib pypdf speechrecognition pydub python-dotenv beautifulsoup4seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d800e-881e-4cf6-8976-d3bd3f5d29b4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81ceaea-f8ae-4679-a2e6-1a63f544c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import tempfile\n",
    "from contextlib import redirect_stdout\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from gradio.themes import Default\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21067612-5578-43ce-b961-75b83fbb652b",
   "metadata": {},
   "source": [
    "#  Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06e9156-f9a4-4140-a3b1-f41d03dca373",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not set in environment\")\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "MODEL = \"gpt-4o\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3870a3c-6206-4d42-9301-584b5c48b25d",
   "metadata": {},
   "source": [
    "# Global state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a46656-5c52-4e83-9a84-1af46d8493c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state = None\n",
    "current_system_prompt = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b585ce46-2f02-4980-9522-5bbca02e9b1a",
   "metadata": {},
   "source": [
    "# System prompt template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c2f813-d340-4a7b-978e-991fdeb8ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are DataBot, an expert data-analysis assistant.  \n",
    "The dataframe columns are: {columns}.  \n",
    "Use only these exact names when calling functions; never invent or guess new ones.\n",
    "\n",
    "Available functions:\n",
    " • ingest_csv(file_path) → load the CSV and refresh column list  \n",
    " • execute_code(code) → run Python code with `df` as the dataframe, return stdout and any plot  \n",
    " \n",
    "\n",
    "when required you can call summarize_csv function to provide summary.\n",
    "\n",
    "Whenever you need to execute any kind of code or plot, generate a Python snippet and call execute_code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec19e8f-6018-43b9-bb28-b7ad51901cff",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b4577f-509a-4b66-9512-f4ee3953c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Tool: ingest_csv —\n",
    "def ingest_csv(file_path: str) -> dict:\n",
    "    global df_state, current_system_prompt\n",
    "    df_state = pd.read_csv(file_path)\n",
    "    cols = df_state.columns.tolist()\n",
    "    current_system_prompt = SYSTEM_PROMPT_TEMPLATE.format(columns=cols)\n",
    "    return {\n",
    "        \"rows\": df_state.shape[0],\n",
    "        \"columns\": cols,\n",
    "        \"dtypes\": df_state.dtypes.astype(str).to_dict()\n",
    "    }\n",
    "# — Tool: summarize_csv —\n",
    "def summarize_csv() -> dict:\n",
    "    if df_state is None:\n",
    "        raise ValueError(\"No dataframe loaded.\")\n",
    "    md = df_state.describe(include=\"all\").round(3).to_markdown()\n",
    "    \n",
    "    return {\"markdown\": md}\n",
    "    \n",
    "# — Tool: execute_code —\n",
    "def execute_code(code: str) -> dict:\n",
    "    \"\"\"\n",
    "    Execute user-provided Python code snippet in a sandboxed namespace\n",
    "    where `df` refers to df_state. Capture stdout and any Matplotlib figure.\n",
    "    \"\"\"\n",
    "    global df_state\n",
    "    if df_state is None:\n",
    "        raise ValueError(\"No DataFrame loaded. Please upload a CSV first.\")\n",
    "    # Prepare namespace\n",
    "    namespace = {\n",
    "        \"df\": df_state,\n",
    "        \"pd\": pd,\n",
    "        \"np\": np,\n",
    "        \"plt\": plt,\n",
    "        \"sns\": sns,\n",
    "    }\n",
    "    # Capture stdout\n",
    "    stdout_buffer = io.StringIO()\n",
    "    fig = None\n",
    "    try:\n",
    "        with redirect_stdout(stdout_buffer):\n",
    "            exec(code, namespace)\n",
    "        # Capture current figure if any\n",
    "        fig = plt.gcf()\n",
    "        img_bytes = None\n",
    "        if fig.axes:\n",
    "            buf = io.BytesIO()\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(buf, format=\"png\")\n",
    "            plt.close(fig)\n",
    "            buf.seek(0)\n",
    "            img_bytes = buf.getvalue()\n",
    "        return {\n",
    "            \"stdout\": stdout_buffer.getvalue(),\n",
    "            \"has_image\": bool(img_bytes),\n",
    "            \"image_bytes\": img_bytes\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error executing code: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e9ad6-3510-4373-a00a-6e3ef498a18f",
   "metadata": {},
   "source": [
    "# Function schemas for LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fda6ef-5a38-4729-8454-b0a8b55c5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_schemas():\n",
    "    return [\n",
    "        {\n",
    "            \"name\": \"ingest_csv\",\n",
    "            \"description\": \"Load a CSV file into a DataFrame.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"file_path\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"file_path\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"execute_code\",\n",
    "            \"description\": \"Execute Python code snippet with `df` loaded, returning stdout and plot if any.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"code\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"code\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"summarize_csv\",\n",
    "            \"description\": \"Return descriptive statistics for numeric and categorical columns as markdown.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467018b-785b-4b12-86db-025edb5a06d4",
   "metadata": {},
   "source": [
    "# Chat logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b4909d-1e9d-4e39-9a15-7e5b3c2275d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, file):\n",
    "    global df_state, current_system_prompt\n",
    "    # Build system prompt\n",
    "    system_msg = current_system_prompt or SYSTEM_PROMPT_TEMPLATE.format(columns=\"(none yet)\")\n",
    "    msgs = [{\"role\": \"system\", \"content\": system_msg}]\n",
    "    # Replay history\n",
    "    for u, b in history:\n",
    "        msgs.append({\"role\": \"user\", \"content\": u})\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": b})\n",
    "    # Decide whether to ingest CSV\n",
    "    if file is not None and df_state is None:\n",
    "        msgs.append({\"role\": \"user\", \"content\": file.name})\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=msgs,\n",
    "            functions=get_function_schemas(),\n",
    "            function_call={\n",
    "                \"name\": \"ingest_csv\",\n",
    "                \"arguments\": json.dumps({\"file_path\": file.name})\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        msgs.append({\"role\": \"user\", \"content\": message})\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=msgs,\n",
    "            functions=get_function_schemas(),\n",
    "            function_call=\"auto\"\n",
    "        )\n",
    "\n",
    "    choice = resp.choices[0].message\n",
    "\n",
    "    # Plain text reply\n",
    "    if choice.content:\n",
    "        history.append((message, choice.content))\n",
    "        return history, None, \"\"\n",
    "\n",
    "    # Function call\n",
    "    fn = choice.function_call.name\n",
    "    args = json.loads(choice.function_call.arguments)\n",
    "    # Attempt tool execution\n",
    "    try:\n",
    "        if fn == \"ingest_csv\":\n",
    "            result = ingest_csv(**args)\n",
    "            tool_result = {\"message\": f\"Loaded CSV with {result['rows']} rows and {len(result['columns'])} columns.\"}\n",
    "            img = None\n",
    "        elif fn == \"execute_code\":\n",
    "            exec_res = execute_code(args[\"code\"])\n",
    "            # Prepare tool result for LLM\n",
    "            tool_result = {\"stdout\": exec_res[\"stdout\"], \"has_image\": exec_res[\"has_image\"]}\n",
    "            img = Image.open(io.BytesIO(exec_res[\"image_bytes\"])) if exec_res[\"has_image\"] else None\n",
    "        elif fn == \"summarize_csv\":\n",
    "            res = summarize_csv()\n",
    "            tool_result = {\"markdown\": res[\"markdown\"]}\n",
    "            img = None\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown function {fn}\")\n",
    "    except Exception as e:\n",
    "        # Send error back to LLM\n",
    "        error_payload = {\"error\": str(e)}\n",
    "        msgs.append({\"role\": \"function\", \"name\": fn, \"content\": json.dumps(error_payload)})\n",
    "        follow = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=msgs\n",
    "        ).choices[0].message.content\n",
    "        history.append((message, follow))\n",
    "        return history, None, \"\"\n",
    "\n",
    "    # Inject function result and get follow-up from LLM\n",
    "    msgs.append({\"role\": \"function\", \"name\": fn, \"content\": json.dumps(tool_result)})\n",
    "    follow = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=msgs\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    label = f\"[Uploaded {file.name}]\" if (fn == \"ingest_csv\") else message\n",
    "    history.append((label, follow))\n",
    "    return history, img, \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8869171-cffa-4ffd-b2a3-264f916d5d49",
   "metadata": {},
   "source": [
    "# Gradio UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce1ac86-06f8-4809-b9de-4f6aa420ba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/48/5m58qpqx65s31d8vcx2418dc0000gn/T/ipykernel_55846/242598804.py:4: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks(theme=Default()) as app:\n",
    "    gr.Markdown(\"## 📊 Data Analysis Chatbot\\nUpload a CSV, then ask me to summarize or plot — I’ll run code under the hood and show you the results.\")\n",
    "    file_input = gr.File(label=\"Upload CSV (.csv)\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(placeholder=\"Type your question…\", label=None)\n",
    "        send = gr.Button(\"Send\")\n",
    "    image_out = gr.Image()\n",
    "\n",
    "    send.click(chat, inputs=[user_input, chatbot, file_input], outputs=[chatbot, image_out, user_input], queue=True)\n",
    "    user_input.submit(chat, inputs=[user_input, chatbot, file_input], outputs=[chatbot, image_out, user_input], queue=True)\n",
    "\n",
    "    app.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70222374-824b-4981-b94f-3c4897ca95ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d1725-5505-429d-91fe-9756675cd88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
